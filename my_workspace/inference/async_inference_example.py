#!/usr/bin/env python3
"""
Kochæœºæ¢°è‡‚å¼‚æ­¥æ¨ç†ç¤ºä¾‹
ä½¿ç”¨LeRobotçš„async inferenceæ¡†æ¶è¿›è¡Œåˆ†å¸ƒå¼æ¨ç†

ä½¿ç”¨æ–¹æ³•:
    # ç»ˆç«¯1: å¯åŠ¨ç­–ç•¥æœåŠ¡å™¨
    python async_inference_example.py --mode server --policy act

    # ç»ˆç«¯2: å¯åŠ¨æœºå™¨äººå®¢æˆ·ç«¯
    python async_inference_example.py --mode client --policy act
"""

import argparse
import json
import logging
import subprocess
import sys
import time
from pathlib import Path

# æ·»åŠ é¡¹ç›®è·¯å¾„
PROJECT_ROOT = Path(__file__).parent.parent.parent
sys.path.insert(0, str(PROJECT_ROOT / "src"))

# è®¾ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# æ¨¡å‹è·¯å¾„
MODEL_PATHS = {
    "act": "/mnt/data/cqy/workspace/lerobot-20251003/output/act_train_20251003_174818_1452/checkpoints/152000/pretrained_model",
    "diffusion": "/mnt/data/cqy/workspace/lerobot-20251003/output/diffusion_train_20251003_222201_5883/checkpoints/108000/pretrained_model"
}

def start_policy_server(policy_type: str, model_path: str, host: str = "localhost", port: int = 8080):
    """å¯åŠ¨ç­–ç•¥æœåŠ¡å™¨"""
    logger.info(f"å¯åŠ¨{policy_type.upper()}ç­–ç•¥æœåŠ¡å™¨...")

    cmd = [
        "python", str(PROJECT_ROOT / "src/lerobot/async_inference/policy_server.py"),
        "--host", host,
        "--port", str(port),
        "--policy_type", policy_type,
        "--pretrained_name_or_path", model_path,
        "--device", "cuda" if torch.cuda.is_available() else "cpu",
        "--fps", "30"
    ]

    logger.info(f"æ‰§è¡Œå‘½ä»¤: {' '.join(cmd)}")

    try:
        process = subprocess.Popen(cmd)
        logger.info(f"âœ“ ç­–ç•¥æœåŠ¡å™¨å·²å¯åŠ¨ (PID: {process.pid})")
        logger.info(f"ğŸŒ æœåŠ¡å™¨åœ°å€: {host}:{port}")

        # ç­‰å¾…æœåŠ¡å™¨å¯åŠ¨
        time.sleep(3)

        return process
    except Exception as e:
        logger.error(f"å¯åŠ¨ç­–ç•¥æœåŠ¡å™¨å¤±è´¥: {e}")
        return None

def start_robot_client(policy_type: str, model_path: str, server_address: str = "localhost:8080"):
    """å¯åŠ¨æœºå™¨äººå®¢æˆ·ç«¯"""
    logger.info(f"å¯åŠ¨æœºå™¨äººå®¢æˆ·ç«¯...")

    # ç›¸æœºé…ç½®JSON
    cameras_config = json.dumps({
        "laptop": {
            "type": "opencv",
            "index_or_path": 0,
            "width": 640,
            "height": 480,
            "fps": 30
        },
        "phone": {
            "type": "opencv",
            "index_or_path": 2,
            "width": 640,
            "height": 480,
            "fps": 30
        }
    })

    cmd = [
        "python", str(PROJECT_ROOT / "src/lerobot/async_inference/robot_client.py"),
        "--robot.type=koch_follower",
        "--robot.port=/dev/ttyUSB0",
        f"--robot.cameras={cameras_config}",
        "--robot.max_relative_target=10.0",
        f"--policy_type={policy_type}",
        f"--pretrained_name_or_path={model_path}",
        f"--server_address={server_address}",
        "--policy_device=cuda",
        "--actions_per_chunk=50",
        "--fps=30",
        "--task=Grasp and place object",
        "--debug_visualize_queue_size=true"
    ]

    logger.info(f"æ‰§è¡Œå‘½ä»¤: {' '.join(cmd[:5])} ...")  # åªæ˜¾ç¤ºå‰å‡ ä¸ªå‚æ•°

    try:
        process = subprocess.Popen(cmd)
        logger.info(f"âœ“ æœºå™¨äººå®¢æˆ·ç«¯å·²å¯åŠ¨ (PID: {process.pid})")

        return process
    except Exception as e:
        logger.error(f"å¯åŠ¨æœºå™¨äººå®¢æˆ·ç«¯å¤±è´¥: {e}")
        return None

def main():
    parser = argparse.ArgumentParser(description="Kochæœºæ¢°è‡‚å¼‚æ­¥æ¨ç†ç¤ºä¾‹")
    parser.add_argument("--mode", choices=["server", "client"], required=True,
                       help="è¿è¡Œæ¨¡å¼")
    parser.add_argument("--policy", choices=["act", "diffusion"], required=True,
                       help="ç­–ç•¥ç±»å‹")
    parser.add_argument("--host", type=str, default="localhost",
                       help="æœåŠ¡å™¨ä¸»æœºåœ°å€")
    parser.add_argument("--port", type=int, default=8080,
                       help="æœåŠ¡å™¨ç«¯å£")

    args = parser.parse_args()

    # è·å–æ¨¡å‹è·¯å¾„
    model_path = MODEL_PATHS[args.policy]

    if not Path(model_path).exists():
        logger.error(f"æ¨¡å‹è·¯å¾„ä¸å­˜åœ¨: {model_path}")
        sys.exit(1)

    print(f"ğŸš€ å¯åŠ¨å¼‚æ­¥æ¨ç†ç¤ºä¾‹")
    print(f"ğŸ“¦ ç­–ç•¥ç±»å‹: {args.policy.upper()}")
    print(f"ğŸ¯ è¿è¡Œæ¨¡å¼: {args.mode}")
    print(f"ğŸ“ æ¨¡å‹è·¯å¾„: {model_path}")
    print("=" * 50)

    try:
        import torch
        if args.mode == "server":
            process = start_policy_server(args.policy, model_path, args.host, args.port)
            if process:
                try:
                    process.wait()
                except KeyboardInterrupt:
                    logger.info("åœæ­¢ç­–ç•¥æœåŠ¡å™¨...")
                    process.terminate()
                    process.wait()
        else:  # client
            server_address = f"{args.host}:{args.port}"
            process = start_robot_client(args.policy, model_path, server_address)
            if process:
                try:
                    process.wait()
                except KeyboardInterrupt:
                    logger.info("åœæ­¢æœºå™¨äººå®¢æˆ·ç«¯...")
                    process.terminate()
                    process.wait()

    except ImportError as e:
        logger.error(f"ç¼ºå°‘ä¾èµ–: {e}")
        logger.error("è¯·ç¡®ä¿å·²å®‰è£… torch: pip install torch")
        sys.exit(1)

if __name__ == "__main__":
    main()